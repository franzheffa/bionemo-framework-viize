scope: perf
time_limit: 1800
key_segments:
  # Modify keys to be renamed (str) or excluded (False) from run identifier. By default, all args under script_args are included.
  num_layers: False
  att_head: False
  h_size: False
  ffn_h_size: False
  stop_steps: False
script_args:
  # All arguments referenced in the script string must be specified here.
  # Arguments not referenced in the script string must have the 'arg' field specified.
  # See jet/core/configs.py for the specification of the configuration class
  workspace: /workspace/bionemo2
  # data_path: /data/20240809_uniref_2024_03/data # todo: change to amplify data
  model: amplify
  variant: train
  precision: bf16-mixed
  max_steps: 1000000
  stop_steps: 600
  gpus: 8
  pp: 1
  tp: 1
  seq_len: 512
  products:
    - config_name: 120M
      nodes: 2
      num_layers: 24
      att_head: 10
      h_size: 640
      ffn_h_size: 2560
      batch_size: 256
    - config_name: 350M
      nodes: 4
      num_layers: 32
      att_head: 15
      h_size: 960
      ffn_h_size: 3840
      batch_size: 128
script: |-
  WANDB_API_KEY=$BIONEMO_WANDB_API_KEY ${variant}_${model} \
    --min-seq-length ${seq_len} \
    --max-seq-length ${seq_len} \
    --num-layers ${num_layers} \
    --num-attention-heads ${att_head} \
    --hidden-size ${h_size} \
    --ffn-hidden-size ${ffn_h_size} \
    --micro-batch-size ${batch_size} \
    --num-steps ${max_steps} \
    --early-stop-on-step ${stop_steps} \
    --pipeline-model-parallel-size ${pp} \
    --tensor-model-parallel-size ${tp} \
    --num-nodes=${nodes} \
    --devices=${gpus} \
    --precision=${precision} \
    --val-check-interval=200 \
    --limit-val-batches=1.0 \
    --log-every-n-steps=50 \
    --create-tensorboard-logger \
    --experiment-name=${batch_size}bs_${nodes}node_${gpus}gpu_${max_steps}s_${precision}prec \
    --result-dir=${tensorboard_dir} \
    --wandb-project=${wandb_project_name} \
    --wandb-group=${model}_${variant}_${config_name}__${target} \
    --wandb-job-type=${pipeline_label} \
    --no-create-checkpoint-callback;
